<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Contador de Flexões com Movimento da Cabeça</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #f3f3f3;
            color: #333;
        }
        video, canvas {
            max-width: 400px;
            width: 100%;
            border: 2px solid #333;
            border-radius: 8px;
            margin-top: 10px;
        }
        #counter {
            font-size: 2rem;
            font-weight: bold;
            margin-top: 20px;
        }
    </style>
    <!-- TensorFlow.js e PoseNet -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
</head>
<body>
    <h1>Contador de Flexões com a Cabeça</h1>
    <video id="video" autoplay playsinline></video>
    <canvas id="output"></canvas>
    <div id="counter">Flexões: 0</div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('output');
        const context = canvas.getContext('2d');
        const counterDisplay = document.getElementById('counter');
        let count = 0;
        let isDownPosition = false;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: "user",
        width: { ideal: 320 },
        height: { ideal: 240 }
    } // Usa a câmera frontal
            });
            video.srcObject = stream;

            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function loadPosenet() {
    return await posenet.load({
        architecture: 'MobileNetV1',
        outputStride: 16, // Um número menor melhora a precisão, mas números maiores aumentam a velocidade
        inputResolution: { width: 320, height: 240 },
        multiplier: 0.5 // Quanto menor, mais rápido, mas menos preciso
    });
}


        function detectPoseInRealTime(video, net) {
            const canvasWidth = 400;
            const canvasHeight = 300;
            video.width = canvasWidth;
            video.height = canvasHeight;
            canvas.width = canvasWidth;
            canvas.height = canvasHeight;

            async function poseDetectionFrame() {
                const pose = await net.estimateSinglePose(video, {
                    flipHorizontal: true
                });

                context.clearRect(0, 0, canvasWidth, canvasHeight);
                context.drawImage(video, 0, 0, canvasWidth, canvasHeight);

                // Desenha os pontos detectados
                pose.keypoints.forEach(keypoint => {
                    if (keypoint.score > 0.6) {
                        context.beginPath();
                        context.arc(keypoint.position.x, keypoint.position.y, 5, 0, 2 * Math.PI);
                        context.fillStyle = "aqua";
                        context.fill();
                    }
                });

                // Detecta posição de flexão usando a posição do nariz
                const nose = pose.keypoints.find(k => k.part === 'nose');

                if (nose && nose.score > 0.6) {
                    const noseY = nose.position.y;

                    // Detecta movimento de flexão para baixo e depois para cima
                    if (noseY > canvasHeight * 0.6 && !isDownPosition) { // Cabeça abaixada
                        isDownPosition = true;
                    } else if (isDownPosition && noseY < canvasHeight * 0.5) { // Cabeça levantada
                        count++;
                        counterDisplay.textContent = `Flexões: ${count}`;
                        isDownPosition = false;
                    }
                }

                requestAnimationFrame(poseDetectionFrame);
            }

            poseDetectionFrame();
        }

        async function main() {
            await setupCamera();
            const net = await loadPosenet();
            detectPoseInRealTime(video, net);
        }

        main();
    </script>
</body>
</html>
